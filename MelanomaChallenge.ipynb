{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Progression bar\n",
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a melanoma classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.measure import find_contours\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage import draw\n",
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "import cv2\n",
    "#from copy import copy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from IPython.display import HTML\n",
    "#from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "import time\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "X_df = df['ImageId']\n",
    "y_df = df['Malignant']\n",
    "X = X_df.values\n",
    "y = y_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IM_000498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IM_000617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IM_000394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IM_000244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IM_000599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ImageId  Malignant\n",
       "0  IM_000498          0\n",
       "1  IM_000617          0\n",
       "2  IM_000394          0\n",
       "3  IM_000244          0\n",
       "4  IM_000599          0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malignant</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ImageId\n",
       "Malignant         \n",
       "0              485\n",
       "1              115"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_counts_df = df.groupby('Malignant').count()\n",
    "labels_counts_df = labels_counts_df.rename(columns={'Malignant': 'count'})\n",
    "labels_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_im = X[1]\n",
    "filename = 'data/im/{}.jpg'.format(name_im)\n",
    "image = imread(filename)\n",
    "filename_Segmentation = 'data/im/{}_Segmentation.jpg'.format(name_im)\n",
    "image_Segmentation = imread(filename_Segmentation) # Value 0 or 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to clean the data. To do that, we will only keep the pictures whose segmentation respect all of those criterias :\n",
    "\n",
    "-  segmentation results with the lesion mask growing into the image border are rejected\n",
    "-  segmentation results without any detected region are rejected\n",
    "-  segmentation results comprising fragments at the image borders are rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean DataFrame has 511 elements, while the old one has 600 elements\n"
     ]
    }
   ],
   "source": [
    "#cdf is the clean dataframe\n",
    "cdf = df.copy()\n",
    "\n",
    "\n",
    "for im in X_df:\n",
    "    #Reading the files\n",
    "    filename_Segmentation = 'data/im/{}_Segmentation.jpg'.format(im)\n",
    "    image_Segmentation = imread(filename_Segmentation) # Value 0 or 255\n",
    "    \n",
    "    #Rejecting segmentations with \"white\" in the border or no segmentation at all\n",
    "    if (np.mean(image_Segmentation[0,:]) != 0 \n",
    "            or np.mean(image_Segmentation[-2,:]) != 0 \n",
    "                    or np.mean(image_Segmentation[0,:]) != 0 \n",
    "                            or np.mean(image_Segmentation[-2,:]) != 0 \n",
    "                                    or np.mean(image_Segmentation) == 0\n",
    "                                            or im == 'IM_000877'):\n",
    "            cdf = cdf[cdf.ImageId != im]\n",
    "\n",
    "index = cdf['ImageId'].values\n",
    "y = cdf['Malignant'].values\n",
    "\n",
    "print(\"Clean DataFrame has {} elements, while the old one has {} elements\".format(len(cdf), len(df)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cdf.to_csv('data/train_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, we can load the previously calculated clean Dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cdf = pd.read_csv('data/train_clean.csv', index_col = 0)\n",
    "index = cdf['ImageId'].values\n",
    "y = cdf['Malignant'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IM_000617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IM_000394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IM_000244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IM_000599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IM_000279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ImageId  Malignant\n",
       "1  IM_000617          0\n",
       "2  IM_000394          0\n",
       "3  IM_000244          0\n",
       "4  IM_000599          0\n",
       "6  IM_000279          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malignant</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ImageId\n",
       "Malignant         \n",
       "0              431\n",
       "1               80"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_counts_cdf = cdf.groupby('Malignant').count()\n",
    "labels_counts_cdf = labels_counts_cdf.rename(columns={'Malignant': 'count'})\n",
    "labels_counts_cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c34d2be97c4edcb53cd354d104b922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectué en 146 secondes\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for im in log_progress(X_test , every = 1, name = \"Images\"):\n",
    "    image_mul_mask, skin_mul_mask = read_image(im)\n",
    "    lesion = Image.fromarray(image_mul_mask)\n",
    "    lesion.save(\"data/im/processed_ims/{}.jpg\".format(im))\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Effectué en {} secondes\".format(round(t2-t1)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 26 different features, including color, border, texture and other local features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_image(im):\n",
    "    filename = 'data/im/{}.jpg'.format(im)\n",
    "    image = imread(filename)\n",
    "    filename_Segmentation = 'data/im/{}_Segmentation.jpg'.format(im)\n",
    "    image_Segmentation = imread(filename_Segmentation) # Value 0 or 255\n",
    "    #Resizing images\n",
    "    (h,w,c) = image.shape\n",
    "    h_new = 300\n",
    "    w_new = round(h_new*w/h)\n",
    "    image = resize(image,(h_new,w_new), mode = 'reflect')\n",
    "    image = (255 * image).astype(np.uint8)\n",
    "    #Applying the segmentation mask\n",
    "    image_Segmentation = resize(image_Segmentation,(h_new,w_new), mode='reflect')\n",
    "    ret,image_Segmentation = cv2.threshold(image_Segmentation,0.5,1,cv2.THRESH_BINARY)\n",
    "    image_Segmentation_boolean = image_Segmentation.astype(np.uint8) # To get uint8\n",
    "    image_Segmentation_expand = np.expand_dims(image_Segmentation_boolean, axis=2)\n",
    "    image_mul_mask = (image_Segmentation_expand*image)\n",
    "    skin_mul_mask = (1-image_Segmentation_expand)*image\n",
    "    return image_mul_mask, skin_mul_mask\n",
    "\n",
    "\n",
    "def dist(coords1, coords2):\n",
    "    return np.sqrt((coords1[0]-coords2[0])**2 + (coords1[1]-coords2[1])**2)\n",
    "\n",
    "def get_longest_diagonal(contours):\n",
    "    max_diag = 0\n",
    "    c1, c2 = [],[]\n",
    "    for coords1 in contours:\n",
    "        for coords2 in contours:\n",
    "            d = dist(coords1,coords2)\n",
    "            if (d > max_diag):\n",
    "                max_diag = d\n",
    "                c1, c2 = coords1, coords2\n",
    "    return [c1,c2]\n",
    "\n",
    "def get_normal_vector(c1,c2):\n",
    "    x = c1[0]-c2[0]\n",
    "    y = c1[1]-c2[1]\n",
    "    if (x==0):\n",
    "        y=1\n",
    "    elif (y==0):\n",
    "        x=1\n",
    "    else:\n",
    "        if (abs(x)<abs(y)):\n",
    "            y = y/x\n",
    "            x = 1\n",
    "        else:\n",
    "            x = -x/y\n",
    "            y = -1\n",
    "    return [-y,x]\n",
    "\n",
    "def is_in(el, arr):\n",
    "    for e in arr:\n",
    "        if (e[0]==el[0] and e[1]==el[1]):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_intersections(start, vec, contour):\n",
    "    x,y = vec\n",
    "    if (x==1):\n",
    "        z=0\n",
    "    else:\n",
    "        z=1\n",
    "    x,y = vec[z], vec[1-z]\n",
    "    int1,int2 = start[:], start[:]\n",
    "    a=0\n",
    "    c=0\n",
    "    increase = True\n",
    "    while not(is_in(int1,contour)) and c<200:\n",
    "        if (x==0):\n",
    "            int1[1]+=1\n",
    "        elif (y==0):\n",
    "            int1[0]+=1\n",
    "        elif (increase):\n",
    "            int1[z]+=1\n",
    "            increase = False\n",
    "        else:\n",
    "            int1[1-z]+=np.sign(y)\n",
    "            a+=1\n",
    "            if (a==abs(y)):\n",
    "                a=0\n",
    "                increase = True\n",
    "        c+=1\n",
    "    a=0\n",
    "    c=0\n",
    "    increase = True\n",
    "    while not(is_in(int2,contour)) and c<200:\n",
    "        if (x==0):\n",
    "            int2[1]-=1\n",
    "        elif (y==0):\n",
    "            int2[0]-=1\n",
    "        elif (increase):\n",
    "            int2[z]-=1\n",
    "            increase = False\n",
    "        else:\n",
    "            int2[1-z]-=np.sign(y)\n",
    "            a+=1\n",
    "            if (a==abs(y)):\n",
    "                a=0\n",
    "                increase = True\n",
    "        c+=1\n",
    "            \n",
    "    return int1, int2           \n",
    "\n",
    "def change_base(Np):\n",
    "    Npa = np.array(Np[:])-Np[2]\n",
    "    Npb = np.array(Np[:])-Np[2]\n",
    "    if (Npb[3,0] == Npb[1,0]):\n",
    "        Npb[:,0] = Npa[:,1]\n",
    "        Npb[:,1] = - Npa[:,0]\n",
    "    else:\n",
    "        a = (Npa[3,1] - Npa[1,1])/((Npa[3,0] - Npa[1,0]))\n",
    "        M = np.array([[1,-a],[a,1]])\n",
    "        Npb = Npb.dot(M)\n",
    "    return Npb\n",
    "\n",
    "def threshold(a,s):\n",
    "    if (a>s):\n",
    "        return 1\n",
    "    elif (a<s):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_features(Xf, im):\n",
    "    ####Reading the files containing the image and the segmentation mask, and combining them\n",
    "    image_mul_mask, skin_mul_mask = read_image(im)\n",
    "\n",
    "\n",
    "    ####Computing min, max, average and std of the normalized H and V channels\n",
    "    im_hsv = cv2.cvtColor(image_mul_mask, cv2.COLOR_RGB2HSV)\n",
    "    int_not0 = im_hsv[np.nonzero(im_hsv[:,:,2])]     #We remove the non-segmented part\n",
    "    skin_hsv = cv2.cvtColor(skin_mul_mask, cv2.COLOR_RGB2HSV).astype(np.double)\n",
    "    skin_int_not0 = skin_hsv[np.nonzero(skin_hsv[:,:,2])]     #We remove the non-segmented part\n",
    "    #Normalization\n",
    "    mean_int_skin = np.mean(skin_int_not0[:,2])\n",
    "    unique, counts = np.unique(skin_int_not0[:,0], return_counts=True)\n",
    "    n_hue_skin = unique[np.argmax(counts)]\n",
    "    int_n_not0 = int_not0 - [mean_int_skin, 0, n_hue_skin]\n",
    "    min_hue, max_hue, mean_hue, std_hue = np.min(int_n_not0[:,0]), np.max(int_n_not0[:,0]), np.mean(int_n_not0[:,0]), np.std(int_n_not0[:,0])\n",
    "    min_int, max_int, mean_int, std_int = np.min(int_n_not0[:,2]), np.max(int_n_not0[:,2]), np.mean(int_n_not0[:,2]), np.std(int_n_not0[:,2])\n",
    "\n",
    "\n",
    "    ####Computing perimeter and area\n",
    "    area = int_not0.shape[0]\n",
    "    contours = find_contours(image_mul_mask[:,:,2],0)\n",
    "    contour = np.concatenate(contours).astype('int')\n",
    "    #image_mul_mask[contour[:,0].astype('int'),contour[:,1].astype('int')].shape   (To get the values of the contour)\n",
    "    per = len(contour)\n",
    "\n",
    "\n",
    "    ####Asymmetry features\n",
    "    c1, c2 = get_longest_diagonal(contour)\n",
    "    #Getting the perpendicular lines\n",
    "    starting_points = []\n",
    "    ratios = []\n",
    "    p=10\n",
    "    normal_vec = get_normal_vector(c1,c2)\n",
    "    for k in range(1,p):\n",
    "        t=k/10\n",
    "        starting_points.append([round(t*c1[0]+(1-t)*c2[0]),round(t*c1[1]+(1-t)*c2[1])])\n",
    "        int1, int2 = get_intersections(starting_points[k-1], normal_vec, contour)\n",
    "        dist1, dist2 = dist(int1,starting_points[k-1]), dist(int2,starting_points[k-1])\n",
    "        if (dist2!=0):\n",
    "            ratios.append(dist1/dist2)\n",
    "        else:\n",
    "            ratios.append(0)\n",
    "    std_asymetry = np.std(ratios)\n",
    "\n",
    "\n",
    "    ####Border features\n",
    "    #Small irregularities\n",
    "    inflexion_points=[0,0,0]\n",
    "    for p in range(per):\n",
    "        if (p<2):\n",
    "            Np = np.concatenate((contour[p-2][np.newaxis],contour[p-1][np.newaxis],contour[p:p+3]))\n",
    "        elif (p+2>=per):\n",
    "            Np = np.concatenate((contour[p-2:p+1],contour[(p+1) % per][np.newaxis],contour[(p+2) % per][np.newaxis]))\n",
    "        else:\n",
    "            Np = contour[p-2:p+3]\n",
    "        Npb = change_base(Np)\n",
    "        Dl = threshold(Npb[0][1],0) + threshold(Npb[1][1],0)\n",
    "        Dr = threshold(Npb[3][1],0) + threshold(Npb[4][1],0)\n",
    "        if (min(abs(Dl),abs(Dr))>=1):\n",
    "            inflexion_points[int(1-np.sign((1+Dl*Dr/abs(Dl*Dr))*(Dl+Dr)))] += 1\n",
    "    inflexion_points = [x / np.sum(inflexion_points) for x in inflexion_points]\n",
    "    #Large irregularities\n",
    "    irregularities=[0,0,0]\n",
    "    for p in range(per):\n",
    "        p1, p2, p3 = contour[p-30], contour[p-15], contour[p]\n",
    "        Vp = (p2[0]-p1[0])*(p3[1]-p1[1]) - (p2[1]-p1[1])*(p3[0]-p1[0])\n",
    "        irregularities[1 - np.sign(Vp)] += 1\n",
    "    irregularities = [x / per for x in irregularities]\n",
    "\n",
    "\n",
    "    Xf.loc[im] = [min_hue, max_hue, mean_hue, std_hue, min_int, max_int, mean_int, std_int, area, per,\n",
    "                  std_asymetry] + ratios + inflexion_points + irregularities      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66fdfc0bd1a46f7aa51a7e65c08a54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectué en 1879 secondes\n"
     ]
    }
   ],
   "source": [
    "cols = ['min_hue', 'max_hue', 'mean_hue', 'std_hue', 'min_int', 'max_int','mean_int', 'std_int', 'area', 'perimeter',\n",
    "        'std_asymetry']+['Ratio{}'.format(i) for i in range(1,10)]+['s_valleys','s_str_lines','s_peaks', 'l_valleys', \n",
    "                                                                    'l_str_lines', 'l_peaks']\n",
    "\n",
    "Xf = pd.DataFrame(columns = cols, index = index)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for im in log_progress(index , every = 1, name = \"Images\"):\n",
    "    compute_features(Xf, im)\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Effectué en {} secondes\".format(round(t2-t1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centering and scaling the features :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m,sigma = [],[]\n",
    "\n",
    "for j in range(Xf.shape[1]):\n",
    "    m.append(np.mean(Xf.iloc[:,j]))\n",
    "    sigma.append(np.std(Xf.iloc[:,j]))\n",
    "    \n",
    "    Xf.iloc[:,j] = (Xf.iloc[:,j] - m[j])/sigma[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xf.to_csv('data/train_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, we can load the previously calculated features Dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xf = pd.read_csv('data/train_features.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_hue</th>\n",
       "      <th>max_hue</th>\n",
       "      <th>mean_hue</th>\n",
       "      <th>std_hue</th>\n",
       "      <th>min_int</th>\n",
       "      <th>max_int</th>\n",
       "      <th>mean_int</th>\n",
       "      <th>std_int</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>...</th>\n",
       "      <th>Ratio6</th>\n",
       "      <th>Ratio7</th>\n",
       "      <th>Ratio8</th>\n",
       "      <th>Ratio9</th>\n",
       "      <th>s_valleys</th>\n",
       "      <th>s_str_lines</th>\n",
       "      <th>s_peaks</th>\n",
       "      <th>l_valleys</th>\n",
       "      <th>l_str_lines</th>\n",
       "      <th>l_peaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IM_000617</th>\n",
       "      <td>-0.391442</td>\n",
       "      <td>-1.47536</td>\n",
       "      <td>-0.661559</td>\n",
       "      <td>-0.671694</td>\n",
       "      <td>0.921894</td>\n",
       "      <td>0.451743</td>\n",
       "      <td>0.608976</td>\n",
       "      <td>-0.415395</td>\n",
       "      <td>-1.25188</td>\n",
       "      <td>-0.6976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773113</td>\n",
       "      <td>0.417941</td>\n",
       "      <td>0.643495</td>\n",
       "      <td>0.134792</td>\n",
       "      <td>-0.862803</td>\n",
       "      <td>0.0883643</td>\n",
       "      <td>0.714648</td>\n",
       "      <td>-0.945552</td>\n",
       "      <td>-0.765781</td>\n",
       "      <td>1.45883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM_000394</th>\n",
       "      <td>-1.25721</td>\n",
       "      <td>0.279076</td>\n",
       "      <td>-1.23143</td>\n",
       "      <td>-0.342971</td>\n",
       "      <td>0.867895</td>\n",
       "      <td>0.918748</td>\n",
       "      <td>0.912507</td>\n",
       "      <td>-0.392405</td>\n",
       "      <td>1.31448</td>\n",
       "      <td>0.572492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267291</td>\n",
       "      <td>0.314388</td>\n",
       "      <td>0.324018</td>\n",
       "      <td>0.621877</td>\n",
       "      <td>0.529725</td>\n",
       "      <td>0.04859</td>\n",
       "      <td>-0.617437</td>\n",
       "      <td>1.32662</td>\n",
       "      <td>-0.711353</td>\n",
       "      <td>-0.965393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM_000244</th>\n",
       "      <td>0.361596</td>\n",
       "      <td>0.861025</td>\n",
       "      <td>0.753603</td>\n",
       "      <td>1.67943</td>\n",
       "      <td>-1.58906</td>\n",
       "      <td>-1.66535</td>\n",
       "      <td>-1.42854</td>\n",
       "      <td>-0.271365</td>\n",
       "      <td>0.973543</td>\n",
       "      <td>0.532801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.470301</td>\n",
       "      <td>-0.356884</td>\n",
       "      <td>-0.281196</td>\n",
       "      <td>-0.489852</td>\n",
       "      <td>1.04223</td>\n",
       "      <td>-0.968856</td>\n",
       "      <td>0.634532</td>\n",
       "      <td>1.60307</td>\n",
       "      <td>-0.466311</td>\n",
       "      <td>-1.40472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM_000599</th>\n",
       "      <td>-0.167235</td>\n",
       "      <td>0.670914</td>\n",
       "      <td>-0.153786</td>\n",
       "      <td>-0.394943</td>\n",
       "      <td>-0.779076</td>\n",
       "      <td>0.000304635</td>\n",
       "      <td>-0.0823261</td>\n",
       "      <td>0.458542</td>\n",
       "      <td>2.2582</td>\n",
       "      <td>0.603161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264681</td>\n",
       "      <td>-0.0681243</td>\n",
       "      <td>-0.380471</td>\n",
       "      <td>-0.504349</td>\n",
       "      <td>-0.937228</td>\n",
       "      <td>0.962392</td>\n",
       "      <td>-0.728957</td>\n",
       "      <td>-0.448519</td>\n",
       "      <td>2.94374</td>\n",
       "      <td>-1.31057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM_000279</th>\n",
       "      <td>-0.431226</td>\n",
       "      <td>-1.47751</td>\n",
       "      <td>-0.653207</td>\n",
       "      <td>-0.690617</td>\n",
       "      <td>0.638399</td>\n",
       "      <td>0.778647</td>\n",
       "      <td>0.816506</td>\n",
       "      <td>-0.879366</td>\n",
       "      <td>-0.707438</td>\n",
       "      <td>-0.39451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0350194</td>\n",
       "      <td>0.625729</td>\n",
       "      <td>1.80776</td>\n",
       "      <td>1.95528</td>\n",
       "      <td>-0.121596</td>\n",
       "      <td>0.0176165</td>\n",
       "      <td>0.0917462</td>\n",
       "      <td>-0.622206</td>\n",
       "      <td>0.256463</td>\n",
       "      <td>0.499517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            min_hue   max_hue  mean_hue   std_hue   min_int      max_int  \\\n",
       "IM_000617 -0.391442  -1.47536 -0.661559 -0.671694  0.921894     0.451743   \n",
       "IM_000394  -1.25721  0.279076  -1.23143 -0.342971  0.867895     0.918748   \n",
       "IM_000244  0.361596  0.861025  0.753603   1.67943  -1.58906     -1.66535   \n",
       "IM_000599 -0.167235  0.670914 -0.153786 -0.394943 -0.779076  0.000304635   \n",
       "IM_000279 -0.431226  -1.47751 -0.653207 -0.690617  0.638399     0.778647   \n",
       "\n",
       "            mean_int   std_int      area perimeter    ...        Ratio6  \\\n",
       "IM_000617   0.608976 -0.415395  -1.25188   -0.6976    ...      0.773113   \n",
       "IM_000394   0.912507 -0.392405   1.31448  0.572492    ...      0.267291   \n",
       "IM_000244   -1.42854 -0.271365  0.973543  0.532801    ...     -0.470301   \n",
       "IM_000599 -0.0823261  0.458542    2.2582  0.603161    ...      0.264681   \n",
       "IM_000279   0.816506 -0.879366 -0.707438  -0.39451    ...     0.0350194   \n",
       "\n",
       "              Ratio7    Ratio8    Ratio9 s_valleys s_str_lines    s_peaks  \\\n",
       "IM_000617   0.417941  0.643495  0.134792 -0.862803   0.0883643   0.714648   \n",
       "IM_000394   0.314388  0.324018  0.621877  0.529725     0.04859  -0.617437   \n",
       "IM_000244  -0.356884 -0.281196 -0.489852   1.04223   -0.968856   0.634532   \n",
       "IM_000599 -0.0681243 -0.380471 -0.504349 -0.937228    0.962392  -0.728957   \n",
       "IM_000279   0.625729   1.80776   1.95528 -0.121596   0.0176165  0.0917462   \n",
       "\n",
       "          l_valleys l_str_lines   l_peaks  \n",
       "IM_000617 -0.945552   -0.765781   1.45883  \n",
       "IM_000394   1.32662   -0.711353 -0.965393  \n",
       "IM_000244   1.60307   -0.466311  -1.40472  \n",
       "IM_000599 -0.448519     2.94374  -1.31057  \n",
       "IM_000279 -0.622206    0.256463  0.499517  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the SMOTE algortihm to generate new samples of the malignant class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = Xf.values\n",
    "sm = SMOTE(random_state = 42)\n",
    "X_res, y_res = sm.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sfs = SequentialFeatureSelector(estimator=knn, k_features= 20, forward=True, floating=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sfs.fit(X_res, y_res)\n",
    "\n",
    "X_sfs = sfs.transform(X_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature tranformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the PCA of our data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20, whiten = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_pca = pca.fit_transform(X_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the right model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5773502691896258"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc = metrics.make_scorer(metrics.matthews_corrcoef, greater_is_better = True)\n",
    "\n",
    "metrics.matthews_corrcoef([0,0,1,1], [0,0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.302 (+/-0.028) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.000 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.421 (+/-0.225) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.324 (+/-0.109) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.510 (+/-0.220) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.422 (+/-0.181) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.607 (+/-0.189) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.432 (+/-0.184) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.413 (+/-0.186) for {'C': 1, 'kernel': 'linear'}\n",
      "0.420 (+/-0.168) for {'C': 10, 'kernel': 'linear'}\n",
      "0.420 (+/-0.168) for {'C': 100, 'kernel': 'linear'}\n",
      "0.413 (+/-0.184) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y_res, test_size=0.4, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "\n",
    "print(\"# Tuning hyper-parameters\")\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                   scoring=mcc)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#knn = KNeighborsClassifier()\n",
    "\n",
    "svm = SVC(C= 1000, gamma = 0.001, kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "####kNN\n",
    "p_grid = {\"n_neighbors\": np.arange(1, 31, 2),\n",
    "        \"metric\": [\"euclidean\", \"cityblock\"]}\n",
    "\n",
    "\n",
    "####SVM\n",
    "#p_grid = [\n",
    "#  {'C': [0.1,1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "#  {'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average and std Cv score : 0.8898642290630461 +- 0.027375830500070645\n"
     ]
    }
   ],
   "source": [
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "clf = GridSearchCV(estimator=knn, param_grid=p_grid, cv=inner_cv)\n",
    "nested_score = cross_val_score(clf, X=X_pca, y=y_res,scoring=\"accuracy\", cv=outer_cv)\n",
    "print(\"Average and std Cv score : {0} +- {1}\".format(nested_score.mean(), nested_score.std() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]), 'metric': ['euclidean', 'cityblock']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_pca, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'cityblock', 'n_neighbors': 1}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting / Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = LinearSVC(C=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=5, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_pca,y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average and std CV score : 0.4206183803087927 +- 0.06076768015456214\n"
     ]
    }
   ],
   "source": [
    "mcc = metrics.make_scorer(metrics.matthews_corrcoef, greater_is_better = True)\n",
    "\n",
    "score = cross_val_score(svm,X=X_pca, y=y_res, cv=10, scoring=mcc)\n",
    "\n",
    "print(\" Average and std CV score : {0} +- {1}\".format(score.mean(), score.std() ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the features from the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test.csv')\n",
    "X_test = test_df['ImageId'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbebc5e37bba400d9cccd53567adb604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectué en 1034 secondes\n"
     ]
    }
   ],
   "source": [
    "cols = ['min_hue', 'max_hue', 'mean_hue', 'std_hue', 'min_int', 'max_int','mean_int', 'std_int', 'area', 'perimeter',\n",
    "        'std_asymetry']+['Ratio{}'.format(i) for i in range(1,10)]+['s_valleys','s_str_lines','s_peaks', 'l_valleys', \n",
    "                                                                    'l_str_lines', 'l_peaks']\n",
    "\n",
    "Xf_test = pd.DataFrame(columns = cols, index = X_test)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for im in log_progress(X_test , every = 1, name = \"Images\"):\n",
    "    compute_features(Xf_test, im)\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Effectué en {} secondes\".format(round(t2-t1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centering and scaling the data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m,sigma = [],[]\n",
    "\n",
    "for j in range(Xf_test.shape[1]):\n",
    "    m.append(np.mean(Xf_test.iloc[:,j]))\n",
    "    sigma.append(np.std(Xf_test.iloc[:,j]))\n",
    "    Xf_test.iloc[:,j] = (Xf_test.iloc[:,j] - m[j])/sigma[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xf_test.to_csv('data/test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise we can load the previously calculated features dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xf_test = pd.read_csv('data/test_features.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_hue</th>\n",
       "      <th>max_hue</th>\n",
       "      <th>mean_hue</th>\n",
       "      <th>std_hue</th>\n",
       "      <th>min_int</th>\n",
       "      <th>max_int</th>\n",
       "      <th>mean_int</th>\n",
       "      <th>std_int</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>...</th>\n",
       "      <th>Ratio6</th>\n",
       "      <th>Ratio7</th>\n",
       "      <th>Ratio8</th>\n",
       "      <th>Ratio9</th>\n",
       "      <th>s_valleys</th>\n",
       "      <th>s_str_lines</th>\n",
       "      <th>s_peaks</th>\n",
       "      <th>l_valleys</th>\n",
       "      <th>l_str_lines</th>\n",
       "      <th>l_peaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IM_000773</th>\n",
       "      <td>0.383450</td>\n",
       "      <td>-1.201211</td>\n",
       "      <td>-0.106902</td>\n",
       "      <td>-0.712265</td>\n",
       "      <td>1.156952</td>\n",
       "      <td>0.145670</td>\n",
       "      <td>0.736934</td>\n",
       "      <td>-1.395463</td>\n",
       "      <td>-1.085773</td>\n",
       "      <td>-1.352526</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.254079</td>\n",
       "      <td>-0.254971</td>\n",
       "      <td>-0.620876</td>\n",
       "      <td>-0.137872</td>\n",
       "      <td>-0.162941</td>\n",
       "      <td>0.363920</td>\n",
       "      <td>-0.473640</td>\n",
       "      <td>-1.743720</td>\n",
       "      <td>-0.795965</td>\n",
       "      <td>2.306557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM_000538</th>\n",
       "      <td>0.192352</td>\n",
       "      <td>0.806828</td>\n",
       "      <td>0.027583</td>\n",
       "      <td>-0.109918</td>\n",
       "      <td>-0.612000</td>\n",
       "      <td>0.161862</td>\n",
       "      <td>-0.146065</td>\n",
       "      <td>1.810615</td>\n",
       "      <td>0.967055</td>\n",
       "      <td>0.350130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113662</td>\n",
       "      <td>-0.234438</td>\n",
       "      <td>-0.663812</td>\n",
       "      <td>-0.143670</td>\n",
       "      <td>-0.970579</td>\n",
       "      <td>0.955974</td>\n",
       "      <td>-0.655047</td>\n",
       "      <td>-0.292438</td>\n",
       "      <td>0.442331</td>\n",
       "      <td>-0.121053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM_000274</th>\n",
       "      <td>-0.779312</td>\n",
       "      <td>0.457392</td>\n",
       "      <td>-0.693171</td>\n",
       "      <td>-0.120063</td>\n",
       "      <td>-0.455077</td>\n",
       "      <td>0.485694</td>\n",
       "      <td>0.189924</td>\n",
       "      <td>1.859368</td>\n",
       "      <td>-1.010060</td>\n",
       "      <td>-1.116483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097648</td>\n",
       "      <td>-0.106542</td>\n",
       "      <td>-0.260152</td>\n",
       "      <td>-0.104140</td>\n",
       "      <td>-0.964192</td>\n",
       "      <td>0.595188</td>\n",
       "      <td>-0.017010</td>\n",
       "      <td>-1.035672</td>\n",
       "      <td>-0.594282</td>\n",
       "      <td>1.477151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM_000817</th>\n",
       "      <td>0.803248</td>\n",
       "      <td>1.026523</td>\n",
       "      <td>0.817053</td>\n",
       "      <td>1.744181</td>\n",
       "      <td>-2.352421</td>\n",
       "      <td>-2.283069</td>\n",
       "      <td>-2.532417</td>\n",
       "      <td>2.151813</td>\n",
       "      <td>-0.740712</td>\n",
       "      <td>-0.858410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013283</td>\n",
       "      <td>-0.025997</td>\n",
       "      <td>-0.152877</td>\n",
       "      <td>-0.112780</td>\n",
       "      <td>-0.401195</td>\n",
       "      <td>0.349607</td>\n",
       "      <td>-0.189336</td>\n",
       "      <td>-1.652968</td>\n",
       "      <td>-0.304896</td>\n",
       "      <td>1.789921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IM_000674</th>\n",
       "      <td>0.709198</td>\n",
       "      <td>0.992700</td>\n",
       "      <td>0.431880</td>\n",
       "      <td>0.698612</td>\n",
       "      <td>0.443665</td>\n",
       "      <td>-0.064820</td>\n",
       "      <td>0.253055</td>\n",
       "      <td>-0.474715</td>\n",
       "      <td>-0.681829</td>\n",
       "      <td>-0.433532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482514</td>\n",
       "      <td>-0.356696</td>\n",
       "      <td>-0.608603</td>\n",
       "      <td>-0.148741</td>\n",
       "      <td>0.994693</td>\n",
       "      <td>-0.845185</td>\n",
       "      <td>0.430805</td>\n",
       "      <td>0.934355</td>\n",
       "      <td>-0.681988</td>\n",
       "      <td>-0.258235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            min_hue   max_hue  mean_hue   std_hue   min_int   max_int  \\\n",
       "IM_000773  0.383450 -1.201211 -0.106902 -0.712265  1.156952  0.145670   \n",
       "IM_000538  0.192352  0.806828  0.027583 -0.109918 -0.612000  0.161862   \n",
       "IM_000274 -0.779312  0.457392 -0.693171 -0.120063 -0.455077  0.485694   \n",
       "IM_000817  0.803248  1.026523  0.817053  1.744181 -2.352421 -2.283069   \n",
       "IM_000674  0.709198  0.992700  0.431880  0.698612  0.443665 -0.064820   \n",
       "\n",
       "           mean_int   std_int      area  perimeter    ...       Ratio6  \\\n",
       "IM_000773  0.736934 -1.395463 -1.085773  -1.352526    ...    -0.254079   \n",
       "IM_000538 -0.146065  1.810615  0.967055   0.350130    ...    -0.113662   \n",
       "IM_000274  0.189924  1.859368 -1.010060  -1.116483    ...     0.097648   \n",
       "IM_000817 -2.532417  2.151813 -0.740712  -0.858410    ...     0.013283   \n",
       "IM_000674  0.253055 -0.474715 -0.681829  -0.433532    ...    -0.482514   \n",
       "\n",
       "             Ratio7    Ratio8    Ratio9  s_valleys  s_str_lines   s_peaks  \\\n",
       "IM_000773 -0.254971 -0.620876 -0.137872  -0.162941     0.363920 -0.473640   \n",
       "IM_000538 -0.234438 -0.663812 -0.143670  -0.970579     0.955974 -0.655047   \n",
       "IM_000274 -0.106542 -0.260152 -0.104140  -0.964192     0.595188 -0.017010   \n",
       "IM_000817 -0.025997 -0.152877 -0.112780  -0.401195     0.349607 -0.189336   \n",
       "IM_000674 -0.356696 -0.608603 -0.148741   0.994693    -0.845185  0.430805   \n",
       "\n",
       "           l_valleys  l_str_lines   l_peaks  \n",
       "IM_000773  -1.743720    -0.795965  2.306557  \n",
       "IM_000538  -0.292438     0.442331 -0.121053  \n",
       "IM_000274  -1.035672    -0.594282  1.477151  \n",
       "IM_000817  -1.652968    -0.304896  1.789921  \n",
       "IM_000674   0.934355    -0.681988 -0.258235  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xf_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_pca = pca.transform(Xf_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we make predictions on the test dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ImageId  Malignant\n",
      "0  IM_000773          0\n",
      "1  IM_000538          0\n",
      "2  IM_000274          0\n"
     ]
    }
   ],
   "source": [
    "prediction = svm.predict(X_test_pca)\n",
    "test_df['Malignant'] = prediction\n",
    "\n",
    "test_df['Malignant'] = test_df['Malignant'].astype(int) # This line is mandatory to be sure to have integer\n",
    "print(test_df.head(3))\n",
    "test_df.to_csv('data/example_test.csv', index=None, sep=',', mode='w') # Save the data in the exemple_test.csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malignant</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ImageId\n",
       "Malignant         \n",
       "0              199\n",
       "1              101"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_counts_test_df = test_df.groupby('Malignant').count()\n",
    "labels_counts_test_df = labels_counts_test_df.rename(columns={'Malignant': 'count'})\n",
    "labels_counts_test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
